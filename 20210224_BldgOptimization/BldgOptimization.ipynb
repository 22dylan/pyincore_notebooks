{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Seaside Building Optimization </center></h1>\n",
    "This code performs a multi-hazard damage analysis and optimization of building mitigation options for Seaside, Oregon.\n",
    "\n",
    "\n",
    "This notebook consists of the following sections:\n",
    "+ [Importing modules and defining recurrence interval](#input)\n",
    "+ [Multi-Hazard damage analysis](#dmg_analysis)\n",
    "  + [Direct economic loss computations](#econ_loss)\n",
    "  + [Repair time estimates](#repair)\n",
    "  + [Population dislocation estimates](#disloc)\n",
    "+ [Optimization](#optimization)\n",
    "  + [Data aggregation](#agg-opt)\n",
    "  + [Optimal solution search](#optimal_search)\n",
    "+ [Plotting Results](#plotting)\n",
    "\n",
    "\n",
    "The mitigation options that are considered at each parcel are:\n",
    "\n",
    "| Mitigation option | Description |\n",
    "| --- | --- |\n",
    "| 0 | Do nothing / Status Quo | \n",
    "| 1 | Retrofit structure to high code |\n",
    "| 2 | Relocate structure outside the inundation zone | \n",
    "| 3 | Decrease repair time | \n",
    "\n",
    "*Notebook developed by [Tarun Adluri](https://www.linkedin.com/in/tarunadluri) and [Dylan Sanderson](https://github.com/22dylan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='input'></a>\n",
    "***\n",
    "### Importing modules and defining recurrence interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter username: TarunAdluri\n",
      "Enter password: ········\n",
      "Connection successful to IN-CORE services. pyIncore version detected: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=20,20\n",
    "\n",
    "from pyincore import IncoreClient, Dataset, FragilityService, MappingSet, DataService\n",
    "from pyincore.analyses.buildingdamage import BuildingDamage\n",
    "from pyincore.analyses.cumulativebuildingdamage import CumulativeBuildingDamage\n",
    "from pyincore.analyses.populationdislocation import PopulationDislocation, PopulationDislocationUtil\n",
    "from pyincore.analyses.housingunitallocation import HousingUnitAllocation\n",
    "client = IncoreClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying recurrence interval to consider\n",
    "\n",
    "| Recurrence Intervals Options |\n",
    "| --- | \n",
    "| 100 |  \n",
    "| 250 | \n",
    "| 500 |  \n",
    "| 1,000 |\n",
    "| 2,500 |\n",
    "| 5,000 |\n",
    "| 10,000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select hazard return period in years (e.g. 500): 1000\n"
     ]
    }
   ],
   "source": [
    "event = int(input(\"Select hazard return period in years (e.g. 500): \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specifiying pyIncore hazard information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_hazard_dict = {100: \"5dfa4058b9219c934b64d495\", \n",
    "                          250: \"5dfa41aab9219c934b64d4b2\",\n",
    "                          500: \"5dfa4300b9219c934b64d4d0\",\n",
    "                          1000: \"5dfa3e36b9219c934b64c231\",\n",
    "                          2500: \"5dfa4417b9219c934b64d4d3\", \n",
    "                          5000: \"5dfbca0cb9219c101fd8a58d\",\n",
    "                         10000: \"5dfa51bfb9219c934b68e6c2\"}\n",
    "\n",
    "tsunami_hazard_dict = {100: \"5bc9e25ef7b08533c7e610dc\", \n",
    "                      250: \"5df910abb9219cd00cf5f0a5\",\n",
    "                      500: \"5df90e07b9219cd00ce971e7\",\n",
    "                      1000: \"5df90137b9219cd00cb774ec\",\n",
    "                      2500: \"5df90761b9219cd00ccff258\",\n",
    "                      5000: \"5df90871b9219cd00ccff273\",\n",
    "                      10000: \"5d27b986b9219c3c55ad37d0\"}\n",
    "\n",
    "# creating path to damage output\n",
    "path_to_dmg = os.path.join(os.getcwd(), 'damage_results')\n",
    "if not os.path.exists(path_to_dmg):\n",
    "    os.makedirs(path_to_dmg)\n",
    "\n",
    "# creating path to dislocation output\n",
    "path_to_dislocation = os.path.join(os.getcwd(), 'dislocation_results')   \n",
    "if not os.path.exists(path_to_dislocation):\n",
    "    os.makedirs(path_to_dislocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dmg_analysis'></a>\n",
    "***\n",
    "<h2><center> Multi-hazard damage analysis </center><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Earthquake building damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    }
   ],
   "source": [
    "# initializing building damage and fragility service\n",
    "bldg_dmg = BuildingDamage(client)   \n",
    "fragility_service = FragilityService(client)\n",
    "\n",
    "# defining building dataset (GIS point layer)\n",
    "bldg_dataset_id = \"5df40388b9219c06cf8b0c80\"\n",
    "bldg_dmg.load_remote_input_dataset(\"buildings\", bldg_dataset_id)\n",
    "\n",
    "retrofit_mapping_ids = [\"5d2789dbb9219c3c553c7977\", \n",
    "                        \"5e99d145f2935b00011900a4\"]\n",
    "\n",
    "for retrofit_i in range(len(retrofit_mapping_ids)):\n",
    "    # specifiying mapping id from fragilites to building types\n",
    "    mapping_id = retrofit_mapping_ids[retrofit_i]\n",
    "    mapping_set = MappingSet(fragility_service.get_mapping(mapping_id))\n",
    "    bldg_dmg.set_input_dataset('dfr3_mapping_set', mapping_set)\n",
    "\n",
    "    bldg_dmg.set_parameter(\"hazard_type\", \"earthquake\")\n",
    "    bldg_dmg.set_parameter(\"num_cpu\", 4)\n",
    "\n",
    "    result_name = os.path.join(path_to_dmg, 'buildings_eq_{}yr_opt{}' .format(event, retrofit_i))\n",
    "    hazard_id = earthquake_hazard_dict[event]\n",
    "    bldg_dmg.set_parameter(\"hazard_id\", hazard_id)\n",
    "    bldg_dmg.set_parameter(\"result_name\", result_name)\n",
    "\n",
    "    bldg_dmg.run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tsunami building damage\n",
    "First running through pyIncore code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing building damage and fragility service\n",
    "bldg_dmg = BuildingDamage(client)   \n",
    "fragility_service = FragilityService(client)\n",
    "\n",
    "# defining building dataset (GIS point layer)\n",
    "bldg_dataset_id = \"5df40388b9219c06cf8b0c80\"\n",
    "bldg_dmg.load_remote_input_dataset(\"buildings\", bldg_dataset_id)\n",
    "\n",
    "# --- running through tsunami building damage with status quo options\n",
    "# specifiying mapping id from fragilites to building types\n",
    "\n",
    "mapping_id = \"5d279bb9b9219c3c553c7fba\"\n",
    "mapping_set = MappingSet(fragility_service.get_mapping(mapping_id))\n",
    "bldg_dmg.set_input_dataset('dfr3_mapping_set', mapping_set)\n",
    "\n",
    "bldg_dmg.set_parameter(\"hazard_type\", \"tsunami\")\n",
    "bldg_dmg.set_parameter(\"num_cpu\", 4)\n",
    "\n",
    "result_name = os.path.join(path_to_dmg, 'buildings_tsu_{}yr_opt0' .format(event))\n",
    "hazard_id = tsunami_hazard_dict[event]\n",
    "bldg_dmg.set_parameter(\"hazard_id\", hazard_id)\n",
    "bldg_dmg.set_parameter(\"result_name\", result_name)\n",
    "\n",
    "bldg_dmg.run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, creating output with relocated structures (i.e. tsunami damage is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsu_data = os.path.join(path_to_dmg, 'buildings_tsu_{}yr_opt0.csv' .format(event))\n",
    "df = pd.read_csv(tsu_data)\n",
    "df['DS_0'] = 1\n",
    "df['DS_1'] = 0\n",
    "df['DS_2'] = 0\n",
    "df['DS_3'] = 0\n",
    "df['LS_0'] = 0\n",
    "df['LS_1'] = 0\n",
    "df['LS_2'] = 0\n",
    "\n",
    "path_out = os.path.join(path_to_dmg, 'buildings_tsu_{}yr_opt1.csv' .format(event))\n",
    "df.to_csv(path_out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-hazard damage analysis\n",
    "\n",
    "| Mitigation option | Description | Earthquake | Tsunami |\n",
    "| --- | --- | --- | --- |\n",
    "| 0 | Do nothing / Status Quo | Status Quo | Status Quo | \n",
    "| 1 | Retrofit structure to high code | Opt1 | Status Quo |\n",
    "| 2 | Relocate structure outside the inundation zone | Status Quo | Opt1 |\n",
    "| 3 | Decrease repair time | Status Quo | Status Quo |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_scenarios = [\n",
    "    ['buildings_eq_{}yr_opt0.csv' .format(event), 'buildings_tsu_{}yr_opt0.csv' .format(event)],\n",
    "    ['buildings_eq_{}yr_opt1.csv' .format(event), 'buildings_tsu_{}yr_opt0.csv' .format(event)],\n",
    "    ['buildings_eq_{}yr_opt0.csv' .format(event), 'buildings_tsu_{}yr_opt1.csv' .format(event)],\n",
    "    ['buildings_eq_{}yr_opt0.csv' .format(event), 'buildings_tsu_{}yr_opt0.csv' .format(event)]\n",
    "]\n",
    "\n",
    "\n",
    "cumulative_bldg_dmg = CumulativeBuildingDamage(client)\n",
    "\n",
    "for i in range(len(cumulative_scenarios)):\n",
    "    pth_to_eq = cumulative_scenarios[i][0]\n",
    "    pth_to_tsu = cumulative_scenarios[i][1]\n",
    "    pth_to_eq = os.path.join(path_to_dmg, pth_to_eq)\n",
    "    pth_to_tsu = os.path.join(path_to_dmg, pth_to_tsu)\n",
    "    \n",
    "    # --- running pyIncore\n",
    "    cumulative_bldg_dmg.set_parameter(\"num_cpu\", 1)\n",
    "\n",
    "    # loading datasets from CSV files into pyincore\n",
    "    eq_damage_dataset = Dataset.from_file(pth_to_eq, \"ergo:buildingDamageVer5\")\n",
    "    tsu_damage_dataset = Dataset.from_file(pth_to_tsu, \"ergo:buildingDamageVer5\")\n",
    "\n",
    "    cumulative_bldg_dmg.set_input_dataset(\"eq_bldg_dmg\", eq_damage_dataset)\n",
    "    cumulative_bldg_dmg.set_input_dataset(\"tsunami_bldg_dmg\", tsu_damage_dataset)\n",
    "\n",
    "    # defining path to output \n",
    "    result_name = os.path.join('buildings_cumulative_{}yr_opt{}' .format(event, i))\n",
    "    result_name = os.path.join(path_to_dmg, result_name)\n",
    "    \n",
    "    cumulative_bldg_dmg.set_parameter(\"result_name\", result_name)\n",
    "\n",
    "    # running analysis\n",
    "    cumulative_bldg_dmg.run_analysis()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing individual hazard results\n",
    "We only care about the multi-hazard case and don't wont too many files hanging around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(path_to_dmg):\n",
    "    for file in os.listdir(path_to_dmg):\n",
    "        if not \"cumulative\" in file:\n",
    "            file = os.path.join(path_to_dmg, file)\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='econ_loss'></a>\n",
    "***\n",
    "### Direct economic loss computations\n",
    "Computing economic losses based on expected damage state and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    }
   ],
   "source": [
    "dmg_rto = [0.005, 0.155, 0.55, 0.90]  # from MAEVIS documentation (damage ratio)\n",
    "\n",
    "# reading in rmv values of each building\n",
    "bldg_dataset_id = \"5df40388b9219c06cf8b0c80\"\n",
    "data_service = DataService(client)\n",
    "dataset = Dataset.from_data_service(bldg_dataset_id, data_service)\n",
    "rd = dataset.get_inventory_reader()\n",
    "\n",
    "\n",
    "struct_typ, guid, rmv, year_built = [], [], [], []\n",
    "for row in rd:\n",
    "    guid.append(row['properties']['guid'])\n",
    "    rmv.append(row['properties']['rmv_improv'])\n",
    "    year_built.append(row['properties']['year_built'])\n",
    "    struct_typ.append(row['properties']['struct_typ'])\n",
    "df = pd.DataFrame({'guid': guid, 'rmv': rmv, 'year_built': year_built,'struct_typ':struct_typ})\n",
    "df.set_index('guid', inplace=True)\n",
    "\n",
    "DS_keys = ['DS_0', 'DS_1', 'DS_2', 'DS_3']\n",
    "for file in os.listdir(path_to_dmg):\n",
    "    \n",
    "    # reading in the results\n",
    "    file = os.path.join(path_to_dmg, file)\n",
    "    df_temp = pd.read_csv(file)\n",
    "    df_temp.set_index('guid', inplace=True)\n",
    "    \n",
    "    # adding real market value column to results if it's not already there\n",
    "    if not 'rmv' in list(df_temp.columns):\n",
    "        df_temp = pd.merge(df_temp, df, left_index=True, right_index=True)\n",
    "    \n",
    "    # computing expected direct economic losses if they do not exist\n",
    "    if not 'econ_loss' in list(df_temp.columns):\n",
    "        df_temp['econ_loss'] = (df_temp[DS_keys]*dmg_rto).sum(axis=1)*df_temp['rmv']      \n",
    "    \n",
    "    # computing expected direct economic losses if they do not exist\n",
    "    if not 'year_built' in list(df_temp.columns):\n",
    "        df_temp['year_built'] = df['year_built']\n",
    "        df_temp['year_built'].replace([0,1,200,2203], 1960)\n",
    "        \n",
    "    # writing back to output\n",
    "    df_temp.to_csv(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='repair'></a>\n",
    "***\n",
    "### Repair time estimates\n",
    "+ Building repair time information is taken from [HAZUS MH 2.1 (Earthquake Model)](https://www.fema.gov/sites/default/files/2020-09/fema_hazus_earthquake-model_technical-manual_2.1.pdf#page=613)  Section 15.2.4.\n",
    "+ HAZUS provides the median values for repair times for each damage state and building type.\n",
    "+ The repair time formulation follows [Kameshwar et al. (2019)](https://www.sciencedirect.com/science/article/pii/S0951832018315163?casa_token=CPiMJq2o8zAAAAAA:Hjr5X2tu2MWfcEG57JVwAMrn9QgiInDG_eoPsUAQXdZJ7VgaI3UyXVqILpD92IPTVG50R5MsaVA), in which only one set of repair time estimates are used for both earthquake and tsunami hazards and across building types.\n",
    "+ Kameshwar et al. (2019) assume that a lognormal restoration model is used for buildings and that the logarithmic dispersion is 0.5.\n",
    "+ Because Monte-Carlo simulation is not implemented for the optimization algorithm, the median values provided by HAZUS that are used to parameterize the lognormal restoration functions are converted to [mean values](https://www.itl.nist.gov/div898/handbook/apr/section1/apr164.htm)\n",
    "\n",
    "\n",
    "| Damage State | Median | Dispersion |\n",
    "| --- | --- | --- |\n",
    "| Insignificant/None | 0.5 | 0.5 |\n",
    "| Moderate | 60 | 0.5 |\n",
    "| Heavy | 360 | 0.5 |\n",
    "| Complete | 720 | 0.5 |\n",
    "\n",
    "The repair time is thus computed as <br>\n",
    "$$Repair = \\sum_{ds} P_{ds} \\mu_{r,ds}$$\n",
    "With \n",
    "+ $P_{ds}$: probability of being in damage state $ds$\n",
    "+ $\\mu_{r,ds}$: mean repair time associated with damage state $ds$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median repair times for DS: None, slight, moderate, extensive, and complete\n",
    "med = np.array([0.5, 60, 360, 720])\n",
    "beta = np.array([0.5, 0.5, 0.5, 0.5])\n",
    "DSs = ['DS_0', 'DS_1', 'DS_2', 'DS_3']\n",
    "\n",
    "# converting median/beta to mean values\n",
    "mean_repair_time = med*np.exp((beta**2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_keys = ['DS_0', 'DS_1', 'DS_2', 'DS_3']\n",
    "cnt = 0\n",
    "for file in os.listdir(path_to_dmg):\n",
    "    \n",
    "    # if mitigation option 3, decrease repair time by half\n",
    "    if cnt == 3:\n",
    "        mean_repair_time = 0.5*mean_repair_time\n",
    "\n",
    "    # reading in the results\n",
    "    file = os.path.join(path_to_dmg, file)\n",
    "    df_temp = pd.read_csv(file)\n",
    "    df_temp.set_index('guid', inplace=True)\n",
    "    \n",
    "    # computing repair times if they do not exist\n",
    "    if not 'repair' in list(df_temp.columns):\n",
    "        df_temp['repair'] = (df_temp[DS_keys]*mean_repair_time).sum(axis=1)      \n",
    "\n",
    "    df_temp.to_csv(file)\n",
    "    cnt += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Interdependent Community Description - Seaside, OR\n",
    "\n",
    "Explore building inventory and social systems. Specifically look at how the building inventory connects with the housing unit inventory using the housing unit allocation.\n",
    "The housing unit allocation method will provide detail demographic characteristics for the community allocated to each structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaside, OR Housing unit inventory, IN-CORE_1bv6_SetupSeaside_FourInventories_2019-08-02_HUinventory.csv\n",
    "housing_unit_inv = \"5d543087b9219c0689b98234\"\n",
    "\n",
    "# Seaside, OR Address point inventory, IN-CORE_1bv6_SetupSeaside_FourInventories_2019-08-02_addresspointinventory.csv\n",
    "address_point_inv = \"5d542fefb9219c0689b981fb\"\n",
    "\n",
    "# Seaside, OR Building inventory, IN-CORE_1bv6_SetupSeaside_FourInventories_2019-08-02_buildinginventory.csv\n",
    "building_inv = \"5df40388b9219c06cf8b0c80\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_services = DataService(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blockid</th>\n",
       "      <th>addrptid</th>\n",
       "      <th>strctid</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>huestimate</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410079511001025</td>\n",
       "      <td>41007000000020005S001001A</td>\n",
       "      <td>41007000000020005S</td>\n",
       "      <td>-123.900452</td>\n",
       "      <td>46.010494</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410079511003005</td>\n",
       "      <td>41007000000020009S001001A</td>\n",
       "      <td>41007000000020009S</td>\n",
       "      <td>-123.932060</td>\n",
       "      <td>45.979836</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410079507002020</td>\n",
       "      <td>41007020802001001S001001A</td>\n",
       "      <td>41007020802001001S</td>\n",
       "      <td>-123.918625</td>\n",
       "      <td>46.017567</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410079507002040</td>\n",
       "      <td>41007020853008001S001001A</td>\n",
       "      <td>41007020853008001S</td>\n",
       "      <td>-123.913643</td>\n",
       "      <td>46.017326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410079507002040</td>\n",
       "      <td>41007020853008002S001001A</td>\n",
       "      <td>41007020853008002S</td>\n",
       "      <td>-123.913643</td>\n",
       "      <td>46.017326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>410079511003077</td>\n",
       "      <td>41007026497001001S001001A</td>\n",
       "      <td>41007026497001001S</td>\n",
       "      <td>-123.942680</td>\n",
       "      <td>45.972363</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>410079511003076</td>\n",
       "      <td>41007026498001001S001001A</td>\n",
       "      <td>41007026498001001S</td>\n",
       "      <td>-123.943321</td>\n",
       "      <td>45.972286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>410079511003002</td>\n",
       "      <td>41007026500001001S001001A</td>\n",
       "      <td>41007026500001001S</td>\n",
       "      <td>-123.941330</td>\n",
       "      <td>45.972206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>410079511003077</td>\n",
       "      <td>41007026501001001S001001A</td>\n",
       "      <td>41007026501001001S</td>\n",
       "      <td>-123.942200</td>\n",
       "      <td>45.972202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>410079511003077</td>\n",
       "      <td>41007026505001001S001001A</td>\n",
       "      <td>41007026505001001S</td>\n",
       "      <td>-123.941589</td>\n",
       "      <td>45.972042</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3687 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              blockid                   addrptid             strctid  \\\n",
       "0     410079511001025  41007000000020005S001001A  41007000000020005S   \n",
       "1     410079511003005  41007000000020009S001001A  41007000000020009S   \n",
       "2     410079507002020  41007020802001001S001001A  41007020802001001S   \n",
       "3     410079507002040  41007020853008001S001001A  41007020853008001S   \n",
       "4     410079507002040  41007020853008002S001001A  41007020853008002S   \n",
       "...               ...                        ...                 ...   \n",
       "5983  410079511003077  41007026497001001S001001A  41007026497001001S   \n",
       "5984  410079511003076  41007026498001001S001001A  41007026498001001S   \n",
       "5985  410079511003002  41007026500001001S001001A  41007026500001001S   \n",
       "5986  410079511003077  41007026501001001S001001A  41007026501001001S   \n",
       "5987  410079511003077  41007026505001001S001001A  41007026505001001S   \n",
       "\n",
       "               x          y  huestimate  residential  \n",
       "0    -123.900452  46.010494           1            1  \n",
       "1    -123.932060  45.979836           1            1  \n",
       "2    -123.918625  46.017567           1            1  \n",
       "3    -123.913643  46.017326           1            1  \n",
       "4    -123.913643  46.017326           1            1  \n",
       "...          ...        ...         ...          ...  \n",
       "5983 -123.942680  45.972363           1            1  \n",
       "5984 -123.943321  45.972286           1            1  \n",
       "5985 -123.941330  45.972206           1            1  \n",
       "5986 -123.942200  45.972202           1            1  \n",
       "5987 -123.941589  45.972042           1            1  \n",
       "\n",
       "[3687 rows x 7 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = pd.read_csv(\"Seaside_addresspointinventory.csv\")\n",
    "population = population.drop_duplicates(subset=['strctid'])\n",
    "population.to_csv(\"seaside_population.csv\")\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyincore.dataset.Dataset at 0x2abce6fde88>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = Dataset.from_file(\"seaside_population.csv\",data_type=\"incore:addressPoints\")\n",
    "address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Housing Unit Allocation \n",
    "https://github.com/IN-CORE/incore-docs/blob/master/notebooks/housingunitallocation.ipynb\n",
    "\n",
    "Rosenheim, Nathanael, Roberto Guidotti, Paolo Gardoni & Walter Gillis Peacock. (2019). Integration of detailed household and housing unit characteristic data with critical infrastructure for post-hazard resilience modeling. Sustainable and Resilient Infrastructure. doi.org/10.1080/23789689.2019.1681821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create housing allocation \n",
    "hua = HousingUnitAllocation(client)\n",
    "\n",
    "# Load input dataset\n",
    "hua.load_remote_input_dataset(\"housing_unit_inventory\", housing_unit_inv)\n",
    "hua.load_remote_input_dataset(\"address_point_inventory\", address_point_inv)\n",
    "#hua.set_input_dataset(\"address_point_inventory\", address)\n",
    "hua.load_remote_input_dataset(\"buildings\", building_inv)\n",
    "\n",
    "# Specify the result name\n",
    "result_name = \"IN-CORE_1bv6_housingunitallocation\"\n",
    "\n",
    "seed = 1238\n",
    "iterations = 1\n",
    "\n",
    "# Set analysis parameters\n",
    "hua.set_parameter(\"result_name\", result_name)\n",
    "hua.set_parameter(\"seed\", seed)\n",
    "hua.set_parameter(\"iterations\", iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'strctid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-8a9db32e1d38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run Housing unit allocation analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhua\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\baseanalysis.py\u001b[0m in \u001b[0;36mrun_analysis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\housingunitallocation\\housingunitallocation.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mseed_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             hua_inventory = self.get_iteration_probabilistic_allocation(\n\u001b[1;32m---> 98\u001b[1;33m                 pop_inv, addr_point_inv, bg_inv, seed_i)\n\u001b[0m\u001b[0;32m     99\u001b[0m             \u001b[0mtemp_output_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\housingunitallocation\\housingunitallocation.py\u001b[0m in \u001b[0;36mget_iteration_probabilistic_allocation\u001b[1;34m(self, housing_unit_inventory, address_point_inventory, building_inventory, seed)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0msorted_housing_unit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_housing_unit_inventory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing_unit_inventory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mcritical_building_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_infrastructure_inventory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maddress_point_inventory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuilding_inventory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0msorted_infrastructure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_infrastructure_inventory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcritical_building_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\housingunitallocation\\housingunitallocation.py\u001b[0m in \u001b[0;36mmerge_infrastructure_inventory\u001b[1;34m(self, address_point_inventory, building_inventory)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \"\"\"\n\u001b[0;32m    152\u001b[0m         \u001b[0msorted_pnt_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddress_point_inventory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"strctid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0msorted_bld_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilding_inventory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"strctid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         addresspt_building_inv = pd.merge(sorted_bld_0, sorted_pnt_0,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   5453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5454\u001b[0m             \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5455\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5457\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'strctid'"
     ]
    }
   ],
   "source": [
    "# Run Housing unit allocation analysis\n",
    "hua.run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve result dataset\n",
    "hua_result = hua.get_output_dataset(\"result\")\n",
    "\n",
    "# Convert dataset to Pandas DataFrame\n",
    "hua_df = hua_result.get_dataframe_from_csv(low_memory=False)\n",
    "\n",
    "# Display top 5 rows of output data\n",
    "hua_df[['guid','numprec','incomegroup']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "hua_df = pd.read_csv(\"IN-CORE_1bv6_housingunitallocation_1238.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Found Issue - to be fixed\n",
    "The building inventory for Seaside has damage state information - a new version of the file needs to be made without the damage data.\n",
    "\n",
    "### Seaside, OR Building inventory, IN-CORE_1bv6_SetupSeaside_FourInventories_2019-08-02_buildinginventory.csv\n",
    "building_inv = \"5d5433edb9219c0689b98344\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strctid</th>\n",
       "      <th>parcelid</th>\n",
       "      <th>landuse</th>\n",
       "      <th>guid</th>\n",
       "      <th>d_sf</th>\n",
       "      <th>addrptid</th>\n",
       "      <th>residential</th>\n",
       "      <th>y</th>\n",
       "      <th>blockid</th>\n",
       "      <th>x</th>\n",
       "      <th>...</th>\n",
       "      <th>livetype</th>\n",
       "      <th>numprec</th>\n",
       "      <th>ownershp</th>\n",
       "      <th>race</th>\n",
       "      <th>hispan</th>\n",
       "      <th>vacancy</th>\n",
       "      <th>gqtype</th>\n",
       "      <th>bgid</th>\n",
       "      <th>randomhu</th>\n",
       "      <th>aphumerge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41007021038001001S</td>\n",
       "      <td>21038.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>e38d8575-7880-4a8c-b6d7-225ab1cf9264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41007021038001001S001001A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.012722</td>\n",
       "      <td>410079507001001</td>\n",
       "      <td>-123.896065</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.100795e+11</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41007020864002002S</td>\n",
       "      <td>20864.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>af5771b4-4f42-4166-b772-78a3706fa8ac</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41007020864002002S001001A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.017498</td>\n",
       "      <td>410079507001001</td>\n",
       "      <td>-123.903427</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.100795e+11</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41007020864002001S</td>\n",
       "      <td>20864.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>37532fb5-5107-478b-ab2c-158eb001c68b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41007020864002001S001001A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.017498</td>\n",
       "      <td>410079507001001</td>\n",
       "      <td>-123.903427</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.100795e+11</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41007020956001001S</td>\n",
       "      <td>20956.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>66d39314-1c68-4634-a82c-8fcb37f529ff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41007020956001001S001001A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.013523</td>\n",
       "      <td>410079507001001</td>\n",
       "      <td>-123.900246</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.100795e+11</td>\n",
       "      <td>0.032571</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41007021145001001S</td>\n",
       "      <td>21145.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>e519ec32-c5eb-422a-be3d-7ff4bb33f1e2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41007021145001001S001001A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.012257</td>\n",
       "      <td>410079507001005</td>\n",
       "      <td>-123.898918</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.100795e+11</td>\n",
       "      <td>0.247678</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              strctid  parcelid  landuse  \\\n",
       "0  41007021038001001S   21038.0    499.0   \n",
       "1  41007020864002002S   20864.0    192.0   \n",
       "2  41007020864002001S   20864.0    192.0   \n",
       "3  41007020956001001S   20956.0    131.0   \n",
       "4  41007021145001001S   21145.0    131.0   \n",
       "\n",
       "                                   guid  d_sf                   addrptid  \\\n",
       "0  e38d8575-7880-4a8c-b6d7-225ab1cf9264   1.0  41007021038001001S001001A   \n",
       "1  af5771b4-4f42-4166-b772-78a3706fa8ac   1.0  41007020864002002S001001A   \n",
       "2  37532fb5-5107-478b-ab2c-158eb001c68b   1.0  41007020864002001S001001A   \n",
       "3  66d39314-1c68-4634-a82c-8fcb37f529ff   1.0  41007020956001001S001001A   \n",
       "4  e519ec32-c5eb-422a-be3d-7ff4bb33f1e2   1.0  41007021145001001S001001A   \n",
       "\n",
       "   residential          y          blockid           x  ...  livetype  \\\n",
       "0          1.0  46.012722  410079507001001 -123.896065  ...         H   \n",
       "1          1.0  46.017498  410079507001001 -123.903427  ...         H   \n",
       "2          1.0  46.017498  410079507001001 -123.903427  ...         H   \n",
       "3          1.0  46.013523  410079507001001 -123.900246  ...         H   \n",
       "4          1.0  46.012257  410079507001005 -123.898918  ...         H   \n",
       "\n",
       "   numprec  ownershp race hispan vacancy  gqtype          bgid  randomhu  \\\n",
       "0      2.0       1.0  1.0    0.0     0.0     0.0  4.100795e+11  0.005397   \n",
       "1      1.0       1.0  1.0    0.0     0.0     0.0  4.100795e+11  0.007199   \n",
       "2      4.0       1.0  1.0    0.0     0.0     0.0  4.100795e+11  0.023555   \n",
       "3      3.0       1.0  1.0    0.0     0.0     0.0  4.100795e+11  0.032571   \n",
       "4      2.0       1.0  1.0    0.0     0.0     0.0  4.100795e+11  0.247678   \n",
       "\n",
       "   aphumerge  \n",
       "0       both  \n",
       "1       both  \n",
       "2       both  \n",
       "3       both  \n",
       "4       both  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hua_df = hua_df.drop(columns= ['insignific','moderate','heavy','complete'])\n",
    "hua_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "hua_df = hua_df.loc[hua_df['aphumerge'] == 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_0081c_\" ><caption>Confirm housing unit characteristic by Race and Ethnicity.</caption><thead>    <tr>        <th class=\"index_name level0\" >race</th>        <th class=\"col_heading level0 col0\" >1.0</th>        <th class=\"col_heading level0 col1\" >2.0</th>        <th class=\"col_heading level0 col2\" >3.0</th>        <th class=\"col_heading level0 col3\" >4.0</th>        <th class=\"col_heading level0 col4\" >5.0</th>        <th class=\"col_heading level0 col5\" >6.0</th>        <th class=\"col_heading level0 col6\" >7.0</th>        <th class=\"col_heading level0 col7\" >Total</th>    </tr>    <tr>        <th class=\"index_name level0\" >Race Ethnicity</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0081c_level0_row0\" class=\"row_heading level0 row0\" >1 White alone, Not Hispanic</th>\n",
       "                        <td id=\"T_0081c_row0_col0\" class=\"data row0 col0\" >2715</td>\n",
       "                        <td id=\"T_0081c_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_0081c_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_0081c_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "                        <td id=\"T_0081c_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_0081c_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "                        <td id=\"T_0081c_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "                        <td id=\"T_0081c_row0_col7\" class=\"data row0 col7\" >2715</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0081c_level0_row1\" class=\"row_heading level0 row1\" >2 Black alone, Not Hispanic</th>\n",
       "                        <td id=\"T_0081c_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_0081c_row1_col1\" class=\"data row1 col1\" >14</td>\n",
       "                        <td id=\"T_0081c_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "                        <td id=\"T_0081c_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "                        <td id=\"T_0081c_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "                        <td id=\"T_0081c_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "                        <td id=\"T_0081c_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "                        <td id=\"T_0081c_row1_col7\" class=\"data row1 col7\" >14</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0081c_level0_row2\" class=\"row_heading level0 row2\" >3 Other Race, Not Hispanic</th>\n",
       "                        <td id=\"T_0081c_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_0081c_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_0081c_row2_col2\" class=\"data row2 col2\" >26</td>\n",
       "                        <td id=\"T_0081c_row2_col3\" class=\"data row2 col3\" >35</td>\n",
       "                        <td id=\"T_0081c_row2_col4\" class=\"data row2 col4\" >5</td>\n",
       "                        <td id=\"T_0081c_row2_col5\" class=\"data row2 col5\" >7</td>\n",
       "                        <td id=\"T_0081c_row2_col6\" class=\"data row2 col6\" >60</td>\n",
       "                        <td id=\"T_0081c_row2_col7\" class=\"data row2 col7\" >133</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0081c_level0_row3\" class=\"row_heading level0 row3\" >4 Any Race, Hispanic</th>\n",
       "                        <td id=\"T_0081c_row3_col0\" class=\"data row3 col0\" >93</td>\n",
       "                        <td id=\"T_0081c_row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "                        <td id=\"T_0081c_row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "                        <td id=\"T_0081c_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "                        <td id=\"T_0081c_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "                        <td id=\"T_0081c_row3_col5\" class=\"data row3 col5\" >84</td>\n",
       "                        <td id=\"T_0081c_row3_col6\" class=\"data row3 col6\" >11</td>\n",
       "                        <td id=\"T_0081c_row3_col7\" class=\"data row3 col7\" >191</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0081c_level0_row4\" class=\"row_heading level0 row4\" >Total</th>\n",
       "                        <td id=\"T_0081c_row4_col0\" class=\"data row4 col0\" >2808</td>\n",
       "                        <td id=\"T_0081c_row4_col1\" class=\"data row4 col1\" >16</td>\n",
       "                        <td id=\"T_0081c_row4_col2\" class=\"data row4 col2\" >27</td>\n",
       "                        <td id=\"T_0081c_row4_col3\" class=\"data row4 col3\" >35</td>\n",
       "                        <td id=\"T_0081c_row4_col4\" class=\"data row4 col4\" >5</td>\n",
       "                        <td id=\"T_0081c_row4_col5\" class=\"data row4 col5\" >91</td>\n",
       "                        <td id=\"T_0081c_row4_col6\" class=\"data row4 col6\" >71</td>\n",
       "                        <td id=\"T_0081c_row4_col7\" class=\"data row4 col7\" >3053</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2abce63e248>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hua_df['Race Ethnicity'] = \"0 Vacant HU No Race Ethnicity Data\"\n",
    "hua_df['Race Ethnicity'].notes = \"Identify Race and Ethnicity Housing Unit Characteristics.\"\n",
    "\n",
    "hua_df.loc[(hua_df['race'] == 1) & (hua_df['hispan'] == 0),'Race Ethnicity'] = \"1 White alone, Not Hispanic\"\n",
    "hua_df.loc[(hua_df['race'] == 2) & (hua_df['hispan'] == 0),'Race Ethnicity'] = \"2 Black alone, Not Hispanic\"\n",
    "hua_df.loc[(hua_df['race'].isin([3,4,5,6,7])) & (hua_df['hispan'] == 0),'Race Ethnicity'] = \"3 Other Race, Not Hispanic\"\n",
    "hua_df.loc[(hua_df['hispan'] == 1),'Race Ethnicity'] = \"4 Any Race, Hispanic\"\n",
    "hua_df.loc[(hua_df['gqtype'] >= 1),'Race Ethnicity'] = \"5 Group Quarters no Race Ethnicity Data\"\n",
    "\n",
    "# Check new variable\n",
    "table_title = \"Confirm housing unit characteristic by Race and Ethnicity.\"\n",
    "pd.crosstab(hua_df['Race Ethnicity'], hua_df['race'], \n",
    "            margins=True, margins_name=\"Total\").style.set_caption(table_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_95a75_\" ><caption>Confirm housing unit characteristic by Race and Ethnicity.</caption><thead>    <tr>        <th class=\"index_name level0\" >hispan</th>        <th class=\"col_heading level0 col0\" >0.0</th>        <th class=\"col_heading level0 col1\" >1.0</th>        <th class=\"col_heading level0 col2\" >Total</th>    </tr>    <tr>        <th class=\"index_name level0\" >Race Ethnicity</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_95a75_level0_row0\" class=\"row_heading level0 row0\" >1 White alone, Not Hispanic</th>\n",
       "                        <td id=\"T_95a75_row0_col0\" class=\"data row0 col0\" >2715</td>\n",
       "                        <td id=\"T_95a75_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_95a75_row0_col2\" class=\"data row0 col2\" >2715</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_95a75_level0_row1\" class=\"row_heading level0 row1\" >2 Black alone, Not Hispanic</th>\n",
       "                        <td id=\"T_95a75_row1_col0\" class=\"data row1 col0\" >14</td>\n",
       "                        <td id=\"T_95a75_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "                        <td id=\"T_95a75_row1_col2\" class=\"data row1 col2\" >14</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_95a75_level0_row2\" class=\"row_heading level0 row2\" >3 Other Race, Not Hispanic</th>\n",
       "                        <td id=\"T_95a75_row2_col0\" class=\"data row2 col0\" >133</td>\n",
       "                        <td id=\"T_95a75_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_95a75_row2_col2\" class=\"data row2 col2\" >133</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_95a75_level0_row3\" class=\"row_heading level0 row3\" >4 Any Race, Hispanic</th>\n",
       "                        <td id=\"T_95a75_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "                        <td id=\"T_95a75_row3_col1\" class=\"data row3 col1\" >191</td>\n",
       "                        <td id=\"T_95a75_row3_col2\" class=\"data row3 col2\" >191</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_95a75_level0_row4\" class=\"row_heading level0 row4\" >Total</th>\n",
       "                        <td id=\"T_95a75_row4_col0\" class=\"data row4 col0\" >2862</td>\n",
       "                        <td id=\"T_95a75_row4_col1\" class=\"data row4 col1\" >191</td>\n",
       "                        <td id=\"T_95a75_row4_col2\" class=\"data row4 col2\" >3053</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2abce647d88>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new variable\n",
    "table_title = \"Confirm housing unit characteristic by Race and Ethnicity.\"\n",
    "pd.crosstab(hua_df['Race Ethnicity'], hua_df['hispan'], \n",
    "            margins=True, margins_name=\"Total\").style.set_caption(table_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_title = \"Table 1. Housing Unit Characteristics by Race and Ethnicity\"\n",
    "table1 = pd.pivot_table(hua_df, values='numprec', index=['Race Ethnicity'],\n",
    "                              margins = True, margins_name = 'Total',\n",
    "                              aggfunc=[len, np.sum], \n",
    "                              fill_value=0).reset_index().rename(\n",
    "                                                            columns={'len': 'Housing Unit',\n",
    "                                                                     'sum' : 'Population',\n",
    "                                                                     'numprec': 'Count'})\n",
    "\n",
    "varformat = {('Housing Unit','Count'): \"{:,}\", ('Population','Count'): \"{:,}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_08d62_ th {\n",
       "          text-align: center;\n",
       "    }</style><table id=\"T_08d62_\" ><caption>Table 1. Housing Unit Characteristics by Race and Ethnicity</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Race Ethnicity</th>        <th class=\"col_heading level0 col1\" >Housing Unit</th>        <th class=\"col_heading level0 col2\" >Population</th>    </tr>    <tr>        <th class=\"blank level1\" ></th>        <th class=\"col_heading level1 col0\" ></th>        <th class=\"col_heading level1 col1\" >Count</th>        <th class=\"col_heading level1 col2\" >Count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_08d62_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_08d62_row0_col0\" class=\"data row0 col0\" >0 Vacant HU No Race Ethnicity Data</td>\n",
       "                        <td id=\"T_08d62_row0_col1\" class=\"data row0 col1\" >1,683</td>\n",
       "                        <td id=\"T_08d62_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08d62_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_08d62_row1_col0\" class=\"data row1 col0\" >1 White alone, Not Hispanic</td>\n",
       "                        <td id=\"T_08d62_row1_col1\" class=\"data row1 col1\" >2,715</td>\n",
       "                        <td id=\"T_08d62_row1_col2\" class=\"data row1 col2\" >5,531</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08d62_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_08d62_row2_col0\" class=\"data row2 col0\" >2 Black alone, Not Hispanic</td>\n",
       "                        <td id=\"T_08d62_row2_col1\" class=\"data row2 col1\" >14</td>\n",
       "                        <td id=\"T_08d62_row2_col2\" class=\"data row2 col2\" >24</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08d62_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_08d62_row3_col0\" class=\"data row3 col0\" >3 Other Race, Not Hispanic</td>\n",
       "                        <td id=\"T_08d62_row3_col1\" class=\"data row3 col1\" >133</td>\n",
       "                        <td id=\"T_08d62_row3_col2\" class=\"data row3 col2\" >327</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08d62_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_08d62_row4_col0\" class=\"data row4 col0\" >4 Any Race, Hispanic</td>\n",
       "                        <td id=\"T_08d62_row4_col1\" class=\"data row4 col1\" >191</td>\n",
       "                        <td id=\"T_08d62_row4_col2\" class=\"data row4 col2\" >711</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08d62_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_08d62_row5_col0\" class=\"data row5 col0\" >5 Group Quarters no Race Ethnicity Data</td>\n",
       "                        <td id=\"T_08d62_row5_col1\" class=\"data row5 col1\" >5</td>\n",
       "                        <td id=\"T_08d62_row5_col2\" class=\"data row5 col2\" >47</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08d62_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_08d62_row6_col0\" class=\"data row6 col0\" >Total</td>\n",
       "                        <td id=\"T_08d62_row6_col1\" class=\"data row6 col1\" >4,741</td>\n",
       "                        <td id=\"T_08d62_row6_col2\" class=\"data row6 col2\" >6,640</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2abce63a948>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1.style.set_caption(table_title).format(varformat).set_table_styles([\n",
    "    dict(selector='th', props=[('text-align', 'center')]),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the Housing Unit Allocation has worked\n",
    "Notice that the population count totals for the community should match (pretty closely) data collected for the 2010 Decennial Census.\n",
    "This can be confirmed by going to data.census.gov\n",
    "\n",
    "https://data.census.gov/cedsci/table?q=DECENNIALPL2010.P1&g=1600000US4165950&tid=DECENNIALSF12010.P1\n",
    "\n",
    "Differences in the housing unit allocation and the Census count may be due to differences between political boundaries and the building inventory. See Rosenheim et al 2019 for more details.\n",
    "\n",
    "The housing unit allocation results will become the input for the dislocation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned HUA file as CSV\n",
    "hua_df.to_csv('IN-CORE_1cv1_housingunitallocation_1238.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create population dislocatin \n",
    "pop_dis = PopulationDislocation(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    }
   ],
   "source": [
    "# Seaside, OR Housing unit allocation, performed at start of notebook\n",
    "housing_unit_alloc = Dataset.from_file('IN-CORE_1cv1_housingunitallocation_1238.csv','incore:housingUnitAllocation')\n",
    "\n",
    "# Seaside, OR \"IN-CORE_1bv6_SetupSeaside_FourInventories_2019-08-02_bgdata.csv\"\n",
    "bg_data = \"5d542bd8b9219c0689b90408\"\n",
    "\n",
    "# Value loss parameters, \"IN-CORE_value_loss_bai09.csv\"\n",
    "value_loss = \"5dfd1069fc33d500081555d8\"\n",
    "\n",
    "# Load input dataset\n",
    "pop_dis.set_input_dataset(\"housing_unit_allocation\", housing_unit_alloc)\n",
    "pop_dis.load_remote_input_dataset(\"block_group_data\", bg_data)\n",
    "pop_dis.load_remote_input_dataset(\"value_poss_param\", value_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "bldg_dmg_result = Dataset.from_file(\"buildings_cumulative_500yr_opt0.csv\", data_type='ergo:buildingDamageVer5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_dis.set_input_dataset(\"building_dmg\",bldg_dmg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_unit_alloc = Dataset.from_file(\"IN-CORE_1cv1_housingunitallocation_1238.csv\", data_type='incore:housingUnitAllocation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create population dislocatin \n",
    "pop_dis = PopulationDislocation(client)\n",
    "\n",
    "# Load input dataset\n",
    "# Joplin, MO, Building damage result\n",
    "pop_dis.set_input_dataset(\"building_dmg\", bldg_dmg_result)\n",
    "pop_dis.set_input_dataset(\"housing_unit_allocation\", housing_unit_alloc)\n",
    "pop_dis.load_remote_input_dataset(\"block_group_data\", bg_data)\n",
    "pop_dis.load_remote_input_dataset(\"value_poss_param\", value_loss)\n",
    "\n",
    "# Specify the result name\n",
    "result_name = \"IN-CORE_1bv6_population_dislocation\"\n",
    "\n",
    "seed = 1111\n",
    "\n",
    "# Set analysis parameters\n",
    "pop_dis.set_parameter(\"result_name\", result_name)\n",
    "pop_dis.set_parameter(\"seed\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DS_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DS_0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-8046c310fa35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpop_dis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\baseanalysis.py\u001b[0m in \u001b[0;36mrun_analysis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\populationdislocation\\populationdislocation.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m# Returns dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mmerged_final_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dislocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_block_inv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mcsv_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"dataframe\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_result_csv_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"result\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_final_inv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dataframe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\populationdislocation\\populationdislocation.py\u001b[0m in \u001b[0;36mget_dislocation\u001b[1;34m(self, seed_i, inventory, value_loss)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m# include random value loss by damage state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mrploss0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopulationDislocationUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DS_0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0mrploss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopulationDislocationUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DS_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mrploss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopulationDislocationUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DS_2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\populationdislocation\\populationdislocationutil.py\u001b[0m in \u001b[0;36mget_random_loss\u001b[1;34m(seed_i, df, damage_state, size)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m# select upper bound and lower bound from input table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdamage_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alpha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdamage_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'beta'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdamage_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ub'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    805\u001b[0m                 \u001b[1;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[1;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[1;31m# We should never have a scalar section here, because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3737\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DS_0'"
     ]
    }
   ],
   "source": [
    "pop_dis.run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='disloc'></a>\n",
    "***\n",
    "### Population dislocation estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'DS_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DS_0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-e0204bd12283>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# running population dislocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mpop_dis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# reading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\baseanalysis.py\u001b[0m in \u001b[0;36mrun_analysis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\populationdislocation\\populationdislocation.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m# Returns dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mmerged_final_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dislocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_block_inv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mcsv_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"dataframe\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_result_csv_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"result\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_final_inv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dataframe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\populationdislocation\\populationdislocation.py\u001b[0m in \u001b[0;36mget_dislocation\u001b[1;34m(self, seed_i, inventory, value_loss)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m# include random value loss by damage state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mrploss0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopulationDislocationUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DS_0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0mrploss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopulationDislocationUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DS_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mrploss2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopulationDislocationUtil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DS_2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pyincore\\analyses\\populationdislocation\\populationdislocationutil.py\u001b[0m in \u001b[0;36mget_random_loss\u001b[1;34m(seed_i, df, damage_state, size)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m# select upper bound and lower bound from input table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdamage_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'alpha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdamage_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'beta'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdamage_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ub'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    805\u001b[0m                 \u001b[1;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[1;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[1;31m# We should never have a scalar section here, because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3737\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PyincoreEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DS_0'"
     ]
    }
   ],
   "source": [
    "pop_dis = PopulationDislocation(client)\n",
    "seed = 1111\n",
    "cnt = 0\n",
    "for file in os.listdir(path_to_dmg):\n",
    "\n",
    "    #Reading in local building damage files\n",
    "    file = os.path.join(path_to_dmg, file)\n",
    "    dmg_data = Dataset.from_file(file, data_type='ergo:buildingDamageVer5')\n",
    "    pop_dis.set_input_dataset(\"building_dmg\", dmg_data)\n",
    "\n",
    "    # loading remote population dislocation data \n",
    "    pop_dis.load_remote_input_dataset(\"housing_unit_allocation\", \"5d543b06b9219c0689b987af\")\n",
    "    pop_dis.load_remote_input_dataset(\"block_group_data\", \"5d542bd8b9219c0689b90408\")\n",
    "    pop_dis.load_remote_input_dataset(\"value_poss_param\", \"5dfd1069fc33d500081555d8\") \n",
    "\n",
    "    # setting population dislocation run information\n",
    "    result_name = \"housing-dislocation-result-opt{}\".format(cnt)\n",
    "    result_name = os.path.join(path_to_dislocation, result_name)\n",
    "    pop_dis.set_parameter(\"result_name\", result_name)\n",
    "    pop_dis.set_parameter(\"seed\", seed)\n",
    "    \n",
    "    # running population dislocation\n",
    "    pop_dis.run_analysis()\n",
    "    \n",
    "    # reading \n",
    "    df = pd.read_csv('{}.csv' .format(result_name))\n",
    "    df.dislocated = df.dislocated.astype(\"int32\")\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.drop_duplicates(subset=['guid'])\n",
    "    df.to_csv(result_name+\".csv\", index=False)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmg_files = os.listdir(path_to_dmg)\n",
    "dslc_files = os.listdir(path_to_dislocation)\n",
    "\n",
    "for i in range(4):\n",
    "    dmg_file = os.path.join(path_to_dmg, dmg_files[i])\n",
    "    dmg_df = pd.read_csv(dmg_file)\n",
    "    dmg_df.set_index('guid', inplace=True)\n",
    "\n",
    "    if not 'dislocated' in list(dmg_df.columns):\n",
    "        dslc_file = os.path.join(path_to_dislocation, dslc_files[i])\n",
    "        dslc_df = pd.read_csv(dslc_file)\n",
    "        dslc_df.set_index('guid', inplace=True)    \n",
    "        dmg_df = pd.merge(dmg_df, dslc_df['dislocated'], how='left', left_index=True, right_index=True)\n",
    "\n",
    "        dmg_df.to_csv(dmg_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing population dislocation results\n",
    "This data has been compiled into the damage anlaysis files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(path_to_dislocation):\n",
    "    for file in os.listdir(path_to_dislocation):\n",
    "        file = os.path.join(path_to_dislocation, file)\n",
    "        os.remove(file)\n",
    "    os.rmdir(path_to_dislocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "<a id='optimization'></a>\n",
    "<h2><center> Optimization </center><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agg-opt'></a>\n",
    "***\n",
    "### Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level0 = pd.read_csv(\"damage_results/buildings_cumulative_{}yr_opt0.csv\".format(event))\n",
    "level0[\"K\"]= 0\n",
    "level0[\"b\"]=1\n",
    "level1 = pd.read_csv(\"damage_results/buildings_cumulative_{}yr_opt1.csv\".format(event))\n",
    "level1[\"K\"]= 1\n",
    "level1[\"b\"]=0\n",
    "level1[\"dislocated\"] = level1.dislocated*0.80\n",
    "level2 = pd.read_csv(\"damage_results/buildings_cumulative_{}yr_opt2.csv\".format(event))\n",
    "level2[\"K\"]= 2\n",
    "level2[\"b\"]=0\n",
    "level2[\"dislocated\"] = level1.dislocated*0.50\n",
    "level3 = pd.read_csv(\"damage_results/buildings_cumulative_{}yr_opt3.csv\".format(event))\n",
    "level3[\"K\"]= 3\n",
    "level3[\"b\"]=0\n",
    "level3[\"dislocated\"] = level1.dislocated*1\n",
    "level0.fillna(0, inplace=True)\n",
    "level1.fillna(0, inplace=True)\n",
    "level2.fillna(0, inplace=True)\n",
    "level3.fillna(0, inplace=True)\n",
    "print(level1[['guid', 'dislocated']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_all_lvls = pd.concat([level0, level1, level2, level3])\n",
    "ss_all_lvls = ss_all_lvls.groupby([\"guid\", \"struct_typ\", \"K\"]).mean().reset_index()\n",
    "ss_all_lvls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='optimization'></a>\n",
    "***\n",
    "### Optimization Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qt_data = ss_all_lvls.copy()\n",
    "qt_data.rename(columns = {'guid':'Z'}, inplace = True)\n",
    "qt_data.rename(columns = {'struct_typ':'S'}, inplace = True)\n",
    "qt_data.rename(columns = {'dislocated':'d_ijk'}, inplace = True)\n",
    "qt_data.rename(columns = {'econ_loss':'l'}, inplace = True)\n",
    "qt_data[\"Q_t_hat\"] = ss_all_lvls.repair/ss_all_lvls.b.sum()\n",
    "qt_data = qt_data.drop(['LS_0', 'LS_1', 'LS_2', 'DS_0','DS_1', 'DS_2', 'DS_3','year_built'], axis=1)\n",
    "qt_data.to_csv(\"seaside_qt_data_{}.csv\".format(event))\n",
    "qt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Buildings:\",qt_data.b.sum())\n",
    "print(\"Repair time:\",np.sum(qt_data.b*qt_data.Q_t_hat))\n",
    "print(\"Buildings Dislocated:\",np.sum(qt_data.b*qt_data.d_ijk))\n",
    "print(\"Economic Loss:\",np.sum(qt_data.b*qt_data.l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level0['k1cost'] = level0.rmv*0.20  #30% of rmv for stategy 1\n",
    "level0['k2cost'] = level0.rmv*1  #100% of rmv for stategy 2\n",
    "level0['k3cost'] = level0.rmv*0.10  #15% of rmv for stategy 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Sc(df_lQaddedb,df):\n",
    "    df_Sc=df_lQaddedb[:]\n",
    "    df_Sc=df_Sc.loc[df_Sc.index.repeat(4)].reset_index(drop=True)\n",
    "    df_Sc[\"K'\"]=[0,1,2,3]*len(df_lQaddedb)\n",
    "    df_Sc.drop([\"b\",\"Q_t_hat\"],axis=1,inplace=True)\n",
    "    df_Sc[\"Sc\"]=0\n",
    "    for index,row in df_Sc.iterrows():\n",
    "        r=df[(df[\"guid\"]==row[\"Z\"])&(df[\"struct_typ\"]==row[\"S\"])]\n",
    "        if row[\"K'\"]<row[\"K\"]:\n",
    "            df_Sc.loc[index,\"Sc\"]=100000000000000\n",
    "        if row[\"K\"]==0:\n",
    "            if row[\"K'\"]==1:\n",
    "                df_Sc.loc[index,\"Sc\"]=r[\"k1cost\"].item()\n",
    "            elif row[\"K'\"]==2:\n",
    "                df_Sc.loc[index,\"Sc\"]=r[\"k2cost\"].item()\n",
    "            elif row[\"K'\"]==3:\n",
    "                df_Sc.loc[index,\"Sc\"]=r[\"k3cost\"].item()\n",
    "#         elif row[\"K\"]==1:\n",
    "#             if row[\"K'\"]==2:\n",
    "#                 df_Sc.loc[index,\"Sc\"]=r[\"k2cost\"].item()\n",
    "#             elif row[\"K'\"]==3:\n",
    "#                 df_Sc.loc[index,\"Sc\"]=r[\"k3cost\"].item()\n",
    "#         elif row[\"K\"]==2:\n",
    "#             if row[\"K'\"]==3:\n",
    "#                 df_Sc.loc[index,\"Sc\"]=r[\"k3cost\"].item()\n",
    "    df_Sc.drop( df_Sc[ df_Sc[\"K'\"]<df_Sc[\"K\"] ].index , inplace=True)\n",
    "    df_Sc = df_Sc[df_Sc[\"K\"]==0]\n",
    "    return df_Sc\n",
    "\n",
    "df_sc = calculate_Sc(qt_data, level0)\n",
    "df_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sc.to_csv(\"seaside_sc_data_{}.csv\".format(event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>\n",
    "***\n",
    "<h2><center> Plotting Results </center><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in building polygon dataset and setting up function to filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in building polygon dataset\n",
    "bldg_dataset_id = \"5d927ab2b9219c06ae8d313c\"\n",
    "data_service = DataService(client)\n",
    "dataset = Dataset.from_data_service(bldg_dataset_id, data_service)\n",
    "rd = dataset.get_inventory_reader()\n",
    "\n",
    "# setting up geodataframe\n",
    "gdf = gpd.GeoDataFrame.from_features([feature for feature in rd], crs=\"EPSG:3857\")\n",
    "gdf = gdf[['guid', 'geometry']]\n",
    "gdf.dropna(subset=['guid'], inplace=True)\n",
    "gdf.drop_duplicates(subset='guid', inplace=True)\n",
    "gdf.set_index('guid', inplace=True)\n",
    "\n",
    "def get_gdf_feats(gdf, path_to_run=None, values=None, k=None):\n",
    "    df = pd.read_csv(path_to_run)\n",
    "    df.set_index('Z', inplace=True)\n",
    "    if values != None:\n",
    "        df = df.loc[df['Values'].isin(values)]\n",
    "    if k != None:\n",
    "        df = df.loc[df['K'].isin(k)]\n",
    "    gdf_new = pd.merge(gdf, df, left_index=True, right_index=True)\n",
    "    return gdf_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- making figure and map\n",
    "fig, ax = plt.subplots(1,1)\n",
    "gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "# plotting all parcels\n",
    "gdf.plot(ax=ax, color='lightblue')\n",
    "\n",
    "# getting a subset of parcels\n",
    "gdf_k0 = get_gdf_feats(gdf, path_to_run='decision_variable_B60_X369.csv', values=[1,2], k=[0])\n",
    "\n",
    "# drawing the subset of parcels on the map\n",
    "gdf_k0.plot(ax=ax, color='salmon')\n",
    "\n",
    "\n",
    "# adding basemap\n",
    "ctx.add_basemap(ax, zoom=15, crs='EPSG:4326', source=ctx.providers.Stamen.TonerLite)\n",
    "# ctx.add_basemap(ax, zoom=15, crs='EPSG:4326', source=ctx.providers.OpenStreetMap.Mapnik)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
